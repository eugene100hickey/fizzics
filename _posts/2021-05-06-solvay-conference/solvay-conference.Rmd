---
title: "Solvay Conference"
description: |
  This is what it looks like to change the world.
author:
  - name: Eugene 
    url: https://fizzics.netlify.app
date: 05-06-2021
categories: [Images, R]
output:
  distill::distill_article:
    self_contained: false
---


We posted previously about FACE++ and the article from [Theresa Kuntzler](https://www.mzes.uni-mannheim.de/socialsciencedatalab/article/extracting-emotions/) showing how to integrate this into R. I couldn't resist taking this for a spin one more time, on this occasion using it to examine one of the most famous conference photographs of them all, the one from the 5th [Solvay Conference](https://en.wikipedia.org/wiki/Solvay_Conference) of 1927.

Here is the photograph, it features a veritable who's-who of physicists and chemists from a century ago. As a physicist, seeing the people that gave rise to so many brilliant theories and techniques always brings a thrill.

![photograph from 5th Solvay Conference](Solvay_conference_1927.jpg).

We ran the image through FACE++ to generate a tibble, called _faces_, of names and emotions. Here it is:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, fig.align="center")

library(data.table)
library(jsonlite)
library(httr)
library(tidyverse)
library(showtext)
library(gt)
library(kableExtra)
```


```{r face-function, echo = F, cache=TRUE}
facepp <- function(fullpath, auth) {
  ## Initilize Object to store API output for single image
  face <- NULL
  ## create empty table to fill with API output
  faces <- data.table(anger = as.numeric(NA), 
                      disgust = as.numeric(NA),
                      fear = as.numeric(NA), 
                      happiness = as.numeric(NA),
                      neutral = as.numeric(NA), 
                      sadness = as.numeric(NA), 
                      surprise = as.numeric(NA),
                      gender = as.character(NA),
                      top = as.numeric(NA),
                      left = as.numeric(NA),
                      facecount = as.numeric(NA), 
                      fullpath = fullpath)
  
  ## run counts the number of image at testing
  ## go over each fullpath and send to API
  ## write API-output in face
  run <- 0
  for (i in 1:length(fullpath)) {
    run <- run + 1
    cat(run, "\n")
    while(is.null(face)) {
      try(
        face <- as.character(httr::RETRY("POST", "https://api-us.faceplusplus.com/facepp/v3/detect",
                                         body = list(api_key  = auth$api_key,
                                                     api_secret = auth$api_secret,
                                                     image_file = upload_file(fullpath[i]),
                                                     return_landmark = 0,
                                                     return_attributes = "emotion,gender"),
                                         times = 2, 
                                         encode = "multipart")),
        silent = FALSE
      )
    }
    
    ## if face is found, extract information and write into data.table
    facecount <- length(fromJSON(face)$faces$face_token)
    
    if (facecount != 0) {
      emotion <- fromJSON(face)$faces$attributes$emotion
      gender <- fromJSON(face)$faces$attributes$gender
      top <- fromJSON(face)$faces$face_rectangle$top
      left <- fromJSON(face)$faces$face_rectangle$left
      
      ## write info to data.table
      faces[faces$fullpath == fullpath[i],][,1:11] <- c(emotion[1,], gender[1,], top[1], left[1], facecount)
      
      ## if more than one face found in image, make df with all info and merge
      if(facecount > 1) {
        faces <- dplyr::union(x = faces, 
                              y = data.table(anger = emotion[,1], 
                                             disgust = emotion[,2],
                                             fear = emotion[,3], 
                                             happiness = emotion[,4],
                                             neutral = emotion[,5], 
                                             sadness = emotion[,6], 
                                             surprise = emotion[,7],
                                             gender = gender[,1],
                                             top = top,
                                             left = left,
                                             facecount = facecount,
                                             fullpath = fullpath[i])) 
      }
      
      face <- NULL
      Sys.sleep(2)
    } else {
      face <- NULL
      Sys.sleep(2)
    }
  }
  return(faces)
}

```

```{r fonts, echo = F, cache = F}
font_add_google("Lemonada", "Lemonada")

showtext_auto()

theme_set(theme_minimal())
theme_update(text = element_text(size = 32, family = "Lemonada"))

my_colours <- paletteer::paletteer_d("yarrr::eternal", n = 7)

myauth <- readRDS("../../../myauth_faceplusplus")
```

```{r faces, cache = T, echo = F, message = F, warning = F, include=FALSE}
mypaths <- list.files(path = "groups/")
mypaths <- glue::glue("groups/{mypaths}")

## Call the function
faces <- facepp(fullpath = mypaths, auth = myauth)

faces <- faces %>% 
  arrange(fullpath, left)


scientists <- faces$fullpath %>% 
  str_remove("groups/") %>% 
  str_remove(".png") %>% 
  str_split("-") %>% 
  unique() %>% 
  unlist()

faces$scientist <- scientists
```


```{r table, fig.height=8}
faces %>% 
  select(scientist, anger:surprise) %>% 
  kable("html") %>%
  kable_styling() %>%
   scroll_box(
    height = "200px",
    box_css = "border: 1px solid #ddd; padding: 5px; ",
    fixed_thead = TRUE
  )
```
<br>

As you can see, the over-riding emotion comes out as being _neutral_. The modern vogue of having a sea of smiling faces for your conference photograph wasn't obviously a thing back in 1927. But there is enough variation to warrant taking a closer look. Below we show boxplots of all seven emotions. The _percentage %_ is transformed to a logit scale to highlight variations. From the outliers we can see signs of _sadness_ and _disgust_ and that someone is particularly _happy_. 

```{r boxplot, preview = T}
my_colours <- paletteer::paletteer_d("yarrr::eternal", n = 7)

box <- faces %>% 
  select(scientist, anger:surprise) %>% 
  pivot_longer(-scientist, names_to = "emotion", values_to = "percentage") %>% 
  ggplot(aes(emotion, percentage %>% gtools::logit(max = 100))) +
  geom_boxplot(aes(fill = emotion), show.legend = F) +
  scale_fill_manual(values = my_colours) +
  labs(x = "", y = "Percentage %") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_text(color = my_colours)) +
  coord_flip()

box_dat <- ggplot_build(box)$data[[1]]

box + 
  geom_segment(data = box_dat, 
               aes(x=xmin, xend=xmax,
                   y=middle, yend=middle), 
               colour="grey80", size=1)
```



<center>

### Heisenberg - Happiness `r faces %>% filter(scientist == "heisenberg") %>% pull(happiness) %>% round(1)` %

![](individuals/heisenberg.png){width=50%}

### Lorentz - Anger `r faces %>% filter(scientist == "lorentz") %>% pull(anger) %>% round(1)` %

![](individuals/lorentz.png){width=50%}


### de Broglie - Sadness `r faces %>% filter(scientist == "debroglie") %>% pull(sadness) %>% round(1)` %

![](individuals/debroglie.png){width=50%}


</center>

It seems that FACE++ is remarkably good at picking up pretty subtle facial expressions, even in a photograph of 29 people from 94 years ago. Not bad.